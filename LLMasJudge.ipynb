{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from apikey import api_key\n",
    "from myTools import *\n",
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "define a text literal called greetings with value \"Hello\" and display greetings on the dashboard as a label.   ```envision\n",
      "greeting = \"Hello\" // define the text literal\n",
      "show label greeting // show the text literal as a label. There should be no 'with' !\n",
      "``` +++\n",
      "title = \"Envision Language\"\n",
      "url = \"language\"\n",
      "description = \"Envision is the Domain-Specific Language (DSL) engineered by Lokad for the specific purpose of the predictive optimization of supply chains. This document is not intended for complete programming beginners, but rather for an audience already familiar with basic programming patterns like Microsoft Excel formulas.\"\n",
      "weight = 1\n",
      "alwaysopen = false\n",
      "+++\n",
      "\n",
      "Envision is the Domain-Specific Language (DSL) engineered by Lokad for the specific purpose of the predictive optimization of supply chains. This document is not intended for complete programming beginners, but rather for an audience already familiar with basic programming patterns like Microsoft Excel formulas.\n",
      "\n",
      "Envision has been designed since day 1 with one key feature in mind: the possibility to perform automated script rewrites if the syntax were to evolve. During the first 5 years of operations, Lokad performed around one hundred incremental rewrites. Those rewrites ensure that all our client companies benefit from the latest version of Envision without having to manually revise their scripts. There are many areas in Envisionâ€™s syntax that we plan to adjust in the future. In this documentation, the areas of evolution that have already been clearly identified are pointed out in the _Roadmap_ notes.\n",
      "\n",
      "Unlike many scripting languages, Envision focuses on delivering a high-degree of _correctness by design_, which means capturing as many issues as possible at **compile time** (the moment when the script is _compiled_) rather than **runtime** (the moment when the script is _run_). Capturing issues at compile time is preferable because whenever the amount of processed data is sizable, a runtime issue can take a long time (several minutes) to manifest itself causing productivity and production reliability problems. This documentation focuses on the _compile-time_ angles of Envision.\n",
      "\n",
      "**Table of contents**\n",
      "{{< toc >}}{{< /toc >}}\n"
     ]
    }
   ],
   "source": [
    "docu =read_file(\"docs/envision-brief.md\")    \n",
    "challenge = read_file(\"mychallenges/\"+\"c000\"+\".md\")\n",
    "\n",
    "# decompose challenge into question and prof_answer\n",
    "\n",
    "question,prof_answer,references=decompose_challenge(challenge)\n",
    "ref_str=create_ref(references)\n",
    "print(question,prof_answer,ref_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```envision\n",
      "greetings = \"Hello\"\n",
      "show label greetings\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "coder_personality=\"You are a proficient coder in the Domain Specific Language called Envision. \\\n",
    "    Your task is to generate response to the given challenge. \\\n",
    "    Some challenges will ask you to generate Envision code,\\\n",
    "    others will ask you to explain given code or answer questions related to the Envision language. \\\n",
    "    Do not output any intermediate thinking or explanation, only give the final answer.\\\n",
    "    Here is the documentation of Envision:\\\n",
    "    ### Documentation\\n\" + docu\n",
    "coder_prompt=question\n",
    "\n",
    "coder_response = client.chat.completions.create(\n",
    "    model='gpt-3.5-turbo',\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": coder_personality},\n",
    "        {\"role\": \"user\", \"content\": coder_prompt}\n",
    "    ],\n",
    "    max_tokens=1000,  # Adjust the number of tokens based on your needs\n",
    "    temperature=0.4,\n",
    ")\n",
    "stud_sentence=coder_response.choices[0].message.content\n",
    "print(stud_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### QUESTION: define a text literal called greetings with value \"Hello\" and display greetings on the dashboard as a label.  \n",
      "### PROFESSOR ANSWER: ```envision\n",
      "greeting = \"Hello\" // define the text literal\n",
      "show label greeting // show the text literal as a label. There should be no 'with' !\n",
      "```\n",
      "### STUDENT ANSWER: ```envision\n",
      "greetings = \"Hello\"\n",
      "show label greetings\n",
      "```\n",
      "The student's answer is **ACCEPTABLE**.\n",
      "\n",
      "- The student correctly defined a text literal called `greetings` with the value \"Hello\".\n",
      "- The student correctly displayed the `greetings` text literal on the dashboard as a label.\n",
      "\n",
      "Therefore, the student's answer fulfills the requirements of the question and is acceptable.\n",
      "\n",
      "The use of `greetings` instead of `greeting` is acceptable as it does not violate any rules or requirements specified in the question or the professor's answer.\n",
      "\n",
      "The student's code is logically correct and achieves the goal set by the question.\n",
      "\n",
      "Therefore, the judgment is 1.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# this personality sticks more to professor's answer.\n",
    "\n",
    "judge_personality_teacherAuthority=\"Your goal is to judge the correctness of STUDENT ANSWER, as an answer to the QUESTION.\\\n",
    "In order to judge the STUDENT ANSWER, you are given the PROFESSOR ANSWER with a piece of related documentation.\\\n",
    "Your main job is not to check the syntax correctness, but the logical correctness.\\\n",
    "If the STUDENT ANSWER does not treat the QUESTION logically, it is UNACCEPTABLE.\\\n",
    "Pay special attention to the comments in the PROFESSOR ANSWER. If these comments include\\\n",
    "a rule and if the STUDENT ANSWER violates it, this is UNACCEPTABLE.\\\n",
    "Adding or omitting a useless print position label like a1b2 in the show command is always ACCEPTABLE.\\\n",
    "The use of extra variable or table to temporarily contain a intermediate quantity is ACCEPTABLE.\\\n",
    "Differences in variable names, column names, table names and label names etc. shall systematically be ACCEPTABLE! \\\n",
    "There are sometimes various ways or logics to treat the same QUESTION, and this is ACCEPTABLE, as long as the goal of the QUESTION is achieved.\\\n",
    "Let's think aloud step by step before making your judgement. Tell each ACCEPTABLE or UNACCEPTABLE point. \\\n",
    "At the end of your output, you should judge 0 if there is anything UNACCEPTABLE (even only 1 mark of UNACCEPTABLE) in the STUDENT ANSWER;\\\n",
    "and judge 1 if everything is ACCEPTABLE. End your judgment by the digit either 0 or 1. \\\n",
    "Here is the piece of related documentation : \\n ## DOCUMENTATION\\n\" + ref_str\n",
    "\n",
    "judge_prompt = \"### QUESTION: \"+question+\"\\n### PROFESSOR ANSWER: \"+prof_answer+\"\\n### STUDENT ANSWER: \"+stud_sentence\n",
    "\n",
    "# Generate a response from the chatbot\n",
    "judge_response = client.chat.completions.create(\n",
    "    model='gpt-3.5-turbo',\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": judge_personality_teacherAuthority},\n",
    "        {\"role\": \"user\", \"content\": judge_prompt}\n",
    "    ],\n",
    "    max_tokens=800,  # Adjust the number of tokens based on your needs\n",
    "    temperature=0.1,\n",
    ")\n",
    "print(judge_prompt)\n",
    "# Print the generated response\n",
    "print(judge_response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "verifier_personality=\"Your task is to summarize the input given by the judge:\\\n",
    "    - If the judge has found nothing unacceptable, you should output 1.\\\n",
    "    - If the judge has found anything unacceptable, you should output 0.\\\n",
    "    - Focus on the last line of the judge's sentence: if it has already announced the final judgement, you should output the same (0 or 1).\\\n",
    "    Do not output anything other than pur digit 0 or 1, without font, punctuation or any special character.\"\n",
    "verifier_response = client.chat.completions.create(\n",
    "    model='gpt-3.5-turbo',\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": verifier_personality},\n",
    "        {\"role\": \"user\", \"content\": judge_response.choices[0].message.content}\n",
    "    ],\n",
    "    max_tokens=800,  # Adjust the number of tokens based on your needs\n",
    "    temperature=0.05,\n",
    ")\n",
    "print(verifier_response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "greetings = \"Hello\"\n",
      "show label greetings\n"
     ]
    }
   ],
   "source": [
    "# extract the 'real' code from the student answer (cut away the '''envision bit at the start and end)\n",
    "def extract_code(stud_sentence):\n",
    "    lines = stud_sentence.strip().split('\\n')\n",
    "    return '\\n'.join(lines[1:-1])\n",
    "print(extract_code(stud_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "# send code to online compiler and check if it compiles\n",
    "\n",
    "def check_compilation(script):\n",
    "    url = \"https://try.lokad.com/w/script/trycompile\"\n",
    "    payload = {\n",
    "        \"Script\": script\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        # Send POST request\n",
    "        response = requests.post(url, json=payload)\n",
    "\n",
    "        # Check for successful response\n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            if result[\"IsCompOk\"]:\n",
    "                return True\n",
    "            else:\n",
    "                print(\"Compilation Failed!\")\n",
    "                for message in result[\"CompMessages\"]:\n",
    "                    print(f\"Error: {message['Text']} (Line: {message['Line']}, Start: {message['Start']}, Length: {message['Length']}, Severity: {message['Severity']})\")\n",
    "                    return False\n",
    "        else:\n",
    "            print(\"Error: Unable to reach the compilation service.\")\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return False\n",
    "\n",
    "        \n",
    "\n",
    "# Example usage\n",
    "check_compilation(extract_code(stud_sentence))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each question, try 3 generation-compilations.\n",
    "# if compiles, further check with judge.\n",
    "def pipeline_verify(challenge,coder_personality,judge_personality=judge_personality_teacherAuthority):\n",
    "\n",
    "    question,prof_answer,references=decompose_challenge(challenge)\n",
    "    ref_str=create_ref(references)    \n",
    "    n_tries=3\n",
    "\n",
    "    for compile_try in range(n_tries):\n",
    "        coder_prompt=question\n",
    "        coder_response = client.chat.completions.create(\n",
    "            model='gpt-3.5-turbo',\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": coder_personality},\n",
    "                {\"role\": \"user\", \"content\": coder_prompt}\n",
    "            ],\n",
    "            max_tokens=1000,  # Adjust the number of tokens based on your needs\n",
    "            temperature=0.2,\n",
    "        )\n",
    "        stud_sentence=coder_response.choices[0].message.content\n",
    "        if (question.split(\"\\n\")[0] ==\\\n",
    "        '# this question expects a textual answer and not generation of code. #'):\n",
    "            print('# theoretical question, no compile.')\n",
    "            break\n",
    "        if(check_compilation(extract_code(stud_sentence))):\n",
    "            print('# compile ok')\n",
    "            break\n",
    "        elif (compile_try==n_tries-1):\n",
    "            print( \"# too many failures !\")\n",
    "            print('# badcode:\\n'+extract_code(stud_sentence))\n",
    "            return stud_sentence,\"too many failures !\",False\n",
    "\n",
    "    judge_prompt = \"### QUESTION: \"+question+\"\\n### PROFESSOR ANSWER: \"+prof_answer+\"\\n### STUDENT ANSWER: \"+stud_sentence\n",
    "    judge_response = client.chat.completions.create(\n",
    "        model='gpt-3.5-turbo',\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": judge_personality+ref_str},\n",
    "            {\"role\": \"user\", \"content\": judge_prompt}\n",
    "        ],\n",
    "        max_tokens=800,  # Adjust the number of tokens based on your needs\n",
    "        temperature=0.2,\n",
    "    )\n",
    "    judge_sentence=judge_response.choices[0].message.content\n",
    "    verifier_response = client.chat.completions.create(\n",
    "    model='gpt-3.5-turbo',\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": verifier_personality},\n",
    "        {\"role\": \"user\", \"content\": judge_sentence}\n",
    "    ],\n",
    "    max_tokens=800,  # Adjust the number of tokens based on your needs\n",
    "    temperature=0.05,\n",
    ")\n",
    "    judge_decision=verifier_response.choices[0].message.content=='1'\n",
    "    print ('# judge_decision:',judge_decision)\n",
    "    if not judge_decision:\n",
    "        print('# badcode:\\n',extract_code(stud_sentence))\n",
    "        print('# judge explanation:\\n',judge_sentence)\n",
    "    return stud_sentence,judge_sentence,judge_decision\n",
    "# a all-in-one function to score a model on a list of challenges\n",
    "def pipeline_score_allchallenge(indexes,coder_personality):\n",
    "    challenges=[read_file(\"mychallenges/\"+index+\".md\") for index in indexes]\n",
    "    score=0\n",
    "    for i in range(len(challenges)):\n",
    "        challenge=challenges[i]\n",
    "        print('\\n### verifying challenge No. '+indexes[i])\n",
    "        _,_,judge_decision=pipeline_verify(challenge,coder_personality)\n",
    "        if (judge_decision): score+=1\n",
    "    print('correct:'+str(score)+' out of '+str(len(challenges))+', '+str(score/len(challenges)*100)+'%')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### verifying challenge No. c000\n",
      "# compile ok\n",
      "# judge_decision: True\n",
      "\n",
      "### verifying challenge No. c001\n",
      "# compile ok\n",
      "# judge_decision: True\n",
      "\n",
      "### verifying challenge No. c002\n",
      "# compile ok\n",
      "# judge_decision: False\n",
      "# badcode:\n",
      " table T = with\n",
      "  [| as N |]\n",
      "  [| 1 |] // line 1\n",
      "  [| 2 |] // line 2\n",
      "  [| 3 |] // line 3\n",
      "\n",
      "where T.N < 3\n",
      "  show table \"Filtered Table\" a1b3 with\n",
      "    T.N\n",
      "# judge explanation:\n",
      " The professor's answer provides a correct example of creating a table, applying a filter, and displaying the filtered content. The `show table` command is correctly formatted with 2 whitespaces after the `where` statement.\n",
      "\n",
      "Now, let's evaluate the student's answer:\n",
      "\n",
      "1. The student creates a table `T` with 3 lines and a column named `N`. This is acceptable as it follows the initial instructions.\n",
      "   \n",
      "2. The student applies a filter `where T.N < 3`. This filter will keep only the lines where `N` is less than 3, which is correct and keeps 2 lines as requested.\n",
      "   \n",
      "3. The `show table` command is used to display the filtered table content. The label \"Filtered Table\" is used, which is acceptable.\n",
      "   \n",
      "4. The `show table` command is not indented with 2 whitespaces after the `where` statement as required by the professor's answer. This deviation makes the formatting incorrect.\n",
      "\n",
      "Based on the evaluation, the student's answer is mostly correct but the indentation of the `show table` command is not in accordance with the professor's answer. Therefore, the student's answer is **UNACCEPTABLE**.\n",
      "\n",
      "### Judgement: 0\n",
      "\n",
      "### verifying challenge No. c003\n",
      "# compile ok\n",
      "# judge_decision: True\n",
      "\n",
      "### verifying challenge No. c004\n",
      "# compile ok\n",
      "# judge_decision: True\n",
      "\n",
      "### verifying challenge No. c005\n",
      "# theoretical question, no compile.\n",
      "# judge_decision: True\n",
      "\n",
      "### verifying challenge No. c006\n",
      "# compile ok\n",
      "# judge_decision: False\n",
      "# badcode:\n",
      " table T = with\n",
      "  [| as Name, as Score |]\n",
      "  [| \"Alice\", 85 |]\n",
      "  [| \"Bob\", 92 |]\n",
      "  [| \"Charlie\", 88 |]\n",
      "  [| \"David\", 90 |]\n",
      "  [| \"Eve\", 87 |]\n",
      "\n",
      "maxScore = max(T.Score)\n",
      "bestName = argmax(T.Name, T.Score)\n",
      "\n",
      "show scalar \"\" a1b2 with maxScore\n",
      "show scalar \"\" c1d2 with bestName\n",
      "# judge explanation:\n",
      " The student answer is not correct.\n",
      "\n",
      "1. The student used `argmax(T.Name, T.Score)` which is incorrect. The `argmax` function should take the value to compare as the first argument and the index that we want to know as the second argument. In this case, it should be `argmax(T.Score, T.Name)`.\n",
      "\n",
      "2. The student used `show scalar` instead of `show label` to display the results.\n",
      "\n",
      "Therefore, the student answer is UNACCEPTABLE.\n",
      "\n",
      "The correct version should be:\n",
      "```envision\n",
      "table T = with\n",
      "  [| as Name, as Score |]\n",
      "  [| \"Alice\", 85 |]\n",
      "  [| \"Bob\", 92 |]\n",
      "  [| \"Charlie\", 88 |]\n",
      "  [| \"David\", 90 |]\n",
      "  [| \"Eve\", 87 |]\n",
      "\n",
      "maxScore = max(T.Score)\n",
      "bestName = argmax(T.Score, T.Name)\n",
      "\n",
      "show label \"best score: {maxScore}\" a1b2\n",
      "show label \"best student: {bestName}\" c1d2\n",
      "```\n",
      "\n",
      "Therefore, the correct judgment is 0.\n",
      "\n",
      "### verifying challenge No. c007\n",
      "Compilation Failed!\n",
      "Error: Function 'argmax' does not take 1 arguments. (Line: 15, Start: 3, Length: 6, Severity: Error)\n",
      "Compilation Failed!\n",
      "Error: Function 'argmax' does not take 1 arguments. (Line: 15, Start: 3, Length: 6, Severity: Error)\n",
      "Compilation Failed!\n",
      "Error: Function 'argmax' does not take 1 arguments. (Line: 15, Start: 3, Length: 6, Severity: Error)\n",
      "# too many failures !\n",
      "# badcode:\n",
      "table Students = with\n",
      "  [| as Name, as Teacher, as Score |]\n",
      "  [| \"Alice\", \"John Doe\", 85 |]\n",
      "  [| \"Bob\", \"Jane Smith\", 70 |]\n",
      "  [| \"Charlie\", \"John Doe\", 95 |]\n",
      "  [| \"David\", \"John Doe\", 80 |]\n",
      "  [| \"Eve\", \"Jane Smith\", 75 |]\n",
      "\n",
      "Students.Successful = Students.Score > 79\n",
      "\n",
      "show table \"Successful Students of John Doe\" a1c5 with\n",
      "  Students[Teacher == \"John Doe\" and Successful]\n",
      "  mean(Students.Score) as \"Mean Score\"\n",
      "  max(Students.Score) as \"Best Score\"\n",
      "  argmax(Students.Score) as \"Best Student\"\n",
      "\n",
      "### verifying challenge No. c008\n",
      "# compile ok\n",
      "# judge_decision: False\n",
      "# badcode:\n",
      " table Catalog = with\n",
      "  [| as Name, as Color |]\n",
      "  [| \"Shirt\", \"blue\" |]\n",
      "  [| \"Hat\", \"red\" |]\n",
      "  [| \"Shoes\", \"green\" |]\n",
      "  [| \"Dress\", \"red\" |]\n",
      "\n",
      "table RedItems = where Catalog.Color == \"red\"\n",
      "\n",
      "show table \"Red Items\" a1b3 with\n",
      "  RedItems.Name\n",
      "# judge explanation:\n",
      " The STUDENT ANSWER is mostly correct and follows the logic of the QUESTION. Here are the points to consider:\n",
      "\n",
      "1. The STUDENT ANSWER correctly defines the table `Catalog` with the specified columns and data.\n",
      "   - ACCEPTABLE\n",
      "\n",
      "2. The creation of the `RedItems` table by filtering `Catalog` for items with the color \"red\" is correct.\n",
      "   - ACCEPTABLE\n",
      "\n",
      "3. The use of the `show` command to display the \"Red Items\" table with the names of red items is correct.\n",
      "   - ACCEPTABLE\n",
      "\n",
      "4. The addition of the print position label `a1b3` in the `show` command is unnecessary and not specified in the QUESTION or the PROFESSOR ANSWER. \n",
      "   - UNACCEPTABLE\n",
      "\n",
      "Overall, the STUDENT ANSWER is mostly correct, but the unnecessary addition of the print position label makes it partially UNACCEPTABLE.\n",
      "\n",
      "Therefore, the final judgment is 0.\n",
      "\n",
      "### verifying challenge No. c009\n",
      "Compilation Failed!\n",
      "Error: Found '.' but expected end-of-line, 'into', operator5, operator4, operator3, operator2, operator1, operator0, 'default' or 'where'. (Line: 13, Start: 46, Length: 1, Severity: Error)\n",
      "Compilation Failed!\n",
      "Error: Found '.' but expected end-of-line, 'into', operator5, operator4, operator3, operator2, operator1, operator0, 'default' or 'where'. (Line: 13, Start: 46, Length: 1, Severity: Error)\n",
      "Compilation Failed!\n",
      "Error: Found '.' but expected end-of-line, 'into', operator5, operator4, operator3, operator2, operator1, operator0, 'default' or 'where'. (Line: 13, Start: 46, Length: 1, Severity: Error)\n",
      "# too many failures !\n",
      "# badcode:\n",
      "table Catalog[item] = with\n",
      "  [| as item, as itemcolor |]\n",
      "  [| \"shirt\", \"blue\" |]\n",
      "  [| \"hat\", \"red\" |]\n",
      "  [| \"shoes\", \"green\" |]\n",
      "\n",
      "table ColorPrices[color] = with\n",
      "  [| as color, as price |]\n",
      "  [| \"blue\", 20 |]\n",
      "  [| \"red\", 15 |]\n",
      "  [| \"green\", 25 |]\n",
      "\n",
      "Catalog.itemprice = ColorPrices[Catalog.item].price\n",
      "\n",
      "show table \"Catalog with Prices\" a1b4 with\n",
      "  Catalog.item\n",
      "  Catalog.itemcolor\n",
      "  Catalog.itemprice\n",
      "\n",
      "### verifying challenge No. c010\n",
      "Compilation Failed!\n",
      "Error: Found 'where' but expected boolean, number, dedent, 'order', 'group', 'enum', 'schema', identifier, markdown template start, text interpolation, '(', 'if', unaryoperator or text. (Line: 19, Start: 3, Length: 5, Severity: Error)\n",
      "Compilation Failed!\n",
      "Error: Found end-of-script but expected 'span', 'where' or indent. (Line: 19, Start: 27, Length: 1, Severity: Error)\n",
      "Compilation Failed!\n",
      "Error: Found end-of-script but expected 'span', 'where' or indent. (Line: 19, Start: 27, Length: 1, Severity: Error)\n",
      "# too many failures !\n",
      "# badcode:\n",
      "table Catalog = with\n",
      "  [| as Item, as OrderDate, as DeliveryDate |]\n",
      "  [| \"item1\", date(2022, 1, 1), date(2022, 1, 15) |]\n",
      "  [| \"item2\", date(2022, 2, 5), date(2022, 2, 20) |]\n",
      "  [| \"item3\", date(2022, 3, 10), date(2022, 3, 30) |]\n",
      "  [| \"item4\", date(2022, 4, 15), date(2022, 5, 10) |]\n",
      "  [| \"item5\", date(2022, 5, 20), date(2022, 6, 15) |]\n",
      "  [| \"item6\", date(2022, 6, 25), date(2022, 7, 20) |]\n",
      "  [| \"item7\", date(2022, 7, 30), date(2022, 8, 25) |]\n",
      "  [| \"item8\", date(2022, 8, 5), date(2022, 8, 30) |]\n",
      "  [| \"item9\", date(2022, 9, 10), date(2022, 9, 30) |]\n",
      "  [| \"item10\", date(2022, 10, 15), date(2022, 11, 10) |]\n",
      "\n",
      "Catalog.Leadtime = Catalog.DeliveryDate - Catalog.OrderDate\n",
      "\n",
      "show table \"Items with Leadtime > 20 days\" a1c6 with\n",
      "  Catalog.Item\n",
      "  Catalog.Leadtime\n",
      "where Catalog.Leadtime > 20\n",
      "\n",
      "### verifying challenge No. c011\n",
      "# compile ok\n",
      "# judge_decision: True\n",
      "\n",
      "### verifying challenge No. c012\n",
      "# compile ok\n",
      "# judge_decision: True\n",
      "\n",
      "### verifying challenge No. mc011\n",
      "Compilation Failed!\n",
      "Error: Found 'cross' but expected 'show', 'with', 'for', 'each', '_', identifier, 'write', 'schema', 'montecarlo', 'autodiff', '@', 'def', 'delete', 'expect', '[|', 'read', '{', 'table', 'loop', 'import', 'return', 'dash', 'sample', 'const', 'export', 'if', 'span', 'where', 'keep' or end-of-script. (Line: 9, Start: 1, Length: 5, Severity: Error)\n",
      "Compilation Failed!\n",
      "Error: Found 'cross' but expected 'show', 'with', 'for', 'each', '_', identifier, 'write', 'schema', 'montecarlo', 'autodiff', '@', 'def', 'delete', 'expect', '[|', 'read', '{', 'table', 'loop', 'import', 'return', 'dash', 'sample', 'const', 'export', 'if', 'span', 'where', 'keep' or end-of-script. (Line: 9, Start: 0, Length: 1, Severity: Error)\n",
      "Compilation Failed!\n",
      "Error: Found 'cross' but expected 'show', 'with', 'for', 'each', '_', identifier, 'write', 'schema', 'montecarlo', 'autodiff', '@', 'def', 'delete', 'expect', '[|', 'read', '{', 'table', 'loop', 'import', 'return', 'dash', 'sample', 'const', 'export', 'if', 'span', 'where', 'keep' or end-of-script. (Line: 9, Start: 1, Length: 5, Severity: Error)\n",
      "# too many failures !\n",
      "# badcode:\n",
      "keep span date = [date(2005, 1, 1) .. date(2005, 1, 31)]\n",
      "\n",
      "table Products = with\n",
      "  [| as Name, as Origin, as Factor |]\n",
      "  [| \"Product A\", \"USA\", 1.2 |]\n",
      "  [| \"Product B\", \"China\", 0.8 |]\n",
      "  [| \"Product C\", \"France\", 1.0 |]\n",
      "\n",
      "cross Products, date with\n",
      "  Quantity = random.poisson(10 into Products)\n",
      "\n",
      "### verifying challenge No. mc012\n",
      "Compilation Failed!\n",
      "Error: Invalid token (Line: 2, Start: 2, Length: 1, Severity: Error)\n",
      "Compilation Failed!\n",
      "Error: Invalid token (Line: 2, Start: 2, Length: 1, Severity: Error)\n",
      "Compilation Failed!\n",
      "Error: Invalid token (Line: 2, Start: 2, Length: 1, Severity: Error)\n",
      "# too many failures !\n",
      "# badcode:\n",
      "\n",
      "```envision\n",
      "table Orders[Pid] = with\n",
      "  [| as Pid, as Date, as Quantity |]\n",
      "  [| \"apple\",  date(2020, 4, 15), 3 |]\n",
      "  [| \"pear\",  date(2020, 4, 16), 7 |]\n",
      "  [| \"orange\", date(2020, 4, 17), 2 |]\n",
      "\n",
      "show scalar \"Date of Orange\" with\n",
      "  Orders.Date[Orders.Pid == \"orange\"]\n",
      "```\n",
      "\n",
      "correct:7 out of 15, 46.666666666666664%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "indexes = [f.split('.')[0] for f in os.listdir('mychallenges') if f.endswith('.md') and f!='description.md']\n",
    "pipeline_score_allchallenge(indexes,coder_personality)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torcher-clone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
